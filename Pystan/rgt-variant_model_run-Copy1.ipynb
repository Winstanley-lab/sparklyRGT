{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am being executed!\n"
     ]
    }
   ],
   "source": [
    "# import stan #Pystan 3, not available on windows\n",
    "import os\n",
    "import model_data as md \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import arviz as az \n",
    "import sparklyRGT as rgt\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 #deletable cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these variables are for extracting the data using model_data.py\n",
    "\n",
    "file_names = ['BH07_raw_free_S29-30.xlsx', 'BH04_raw_acquisition.xlsx'] \n",
    "df = rgt.load_data(file_names)\n",
    "\n",
    "fnames = ['']#change these to the names of the csv files\n",
    "\n",
    "#creates lists of subject #s for each unique task\n",
    "task_list = df.groupby(['MSN'])['Subject'].unique()\n",
    "\n",
    "\n",
    "#these lines of code concatenate together the lists of subjects that run the same task (i.e., puts version A \n",
    "#and version B together) - based on unique string for each task name\n",
    "\n",
    "## creates list of subject #s or trial-by-trial data*** --> concatenates together the subjects that run the same task (ex. cuedRGTA and cuedRGTB)\n",
    "## based on unique string for each task name (ex. cued)\n",
    "\n",
    "# uncued_subs = np.concatenate(task_list[[task for task in df.MSN.unique() if 'Classic' in task]])\n",
    "# standard_subs = ...\n",
    "#...\n",
    "\n",
    "# subs = [uncued_subs,standard_subs]\n",
    "\n",
    "numsessions = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change directory to where the csv files are saved\n",
    "os.chdir('../phd_data')\n",
    "\n",
    "#use model_data python script to extract data (a bit slow)\n",
    "uncued = md.get_model_data(fnames, subs[0], numsessions)\n",
    "standard = md.get_model_data(fnames, subs[1], numsessions)\n",
    "reverse = md.get_model_data(fnames, subs[2], numsessions)\n",
    "outcome = md.get_model_data(fnames, subs[3], numsessions)\n",
    "random = md.get_model_data(fnames, subs[4], numsessions)\n",
    "loss = md.get_model_data(fnames, subs[5], numsessions)\n",
    "\n",
    "##model_data takes fnames (same for all variables), list of subject #s and number of sessions (ex. 5, same for all variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile stan code\n",
    "# have to figure out how to pass basic_model as an object, or ideally we can just give it a file name\n",
    "# have to figure out what random_seed is all about \n",
    "basic_standard = stan.build(basic_model, data=uncued, random_seed=1)\n",
    "\n",
    "#do the sampling\n",
    "# have to figure out whether num_samples includes warmup\n",
    "fit_basic_standard = posterior.sample(num_chains=4, num_samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model_data.py test boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_data(fnames,numsessions, subjects, reset_sessions = True):\n",
    "    #fnames is a list of strings with the full file locations for each dataset to be loaded in\n",
    "    df_all = load_multiple_data(fnames, reset_sessions = reset_sessions)\n",
    "    df = extract_data(df_all, numsessions, subjects)\n",
    "    df = get_options(df)\n",
    "    startSubject = start_subject(df)\n",
    "    startSession = start_session(df)\n",
    "    model_data = get_data_dict(df, startSubject, startSession)\n",
    "    return model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = md.load_multiple_data(file_names, reset_sessions = True)\n",
    "data\n",
    "#changed subject # (added 100, 200, etc.) and changed session (to start from 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(\"load_multiple_data_ex-1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [125, 126, 127]\n",
    "df_extract = md.extract_data_chosen(data, numsessions, subjects)\n",
    "df_extract\n",
    "## ran into keyerror for Index(['Option']***\n",
    "## made a duplicate function that uses chosen (just to test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_data = md.start_subject(data)\n",
    "# subject_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_data = md.start_session(data)\n",
    "# session_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df.Subject.unique())\n",
    "ntr = len(df)\n",
    "\n",
    "C = list(df.Chosen)\n",
    "R = list(df.Pellets)\n",
    "P = list(df.Pun_Dur)\n",
    "\n",
    "model_data = {'N': N, \n",
    "                'ntr': ntr,\n",
    "                'startSubject': subject_data,\n",
    "                'startSession': session_data,\n",
    "                'C': C, \n",
    "                'R': R, \n",
    "                'P': P, }\n",
    "# model_data\n",
    "model_data['N']\n",
    "## model data stores the dict containing N, ntr, etc.\n",
    "## model_data is all the information we need to pass to the model!!! (C, R, P, and O contain the \"data\" or \"decisions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = md.get_data_dict(data, subject_data, session_data) \n",
    "## creates a dict with all the desired key-value pairs (ex. N, ntr, P, etc.)\n",
    "## recall: dict is a collection of key-value pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_data.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to models..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_su = basic.sampling(data = saline_uncued, iter = 1600, warmup = 800, chains = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_rc = basic.sampling(data = rop_cued, iter = 2000, warmup = 1000, chains = 4, control={'max_treedepth': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_ru = basic.sampling(data = rop_uncued, iter = 2000, warmup = 1000, chains = 4, control={'max_treedepth': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic2_sc = basic2.sampling(data = saline_cued, iter = 1600, warmup = 800, chains = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic2_su = basic2.sampling(data = saline_uncued, iter = 1600, warmup = 800, chains = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic2_rc = basic2.sampling(data = rop_cued, iter = 1600, warmup = 800, chains = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic2_ru = basic2.sampling(data = rop_uncued, iter = 1600, warmup = 800, chains = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pscale_sc = pscale.sampling(data = saline_cued, iter = 2000, warmup = 1000, chains = 4,\n",
    "                           control={'adapt_delta': 0.99, 'max_treedepth':12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pscale_su = pscale.sampling(data = saline_uncued, iter = 2000, warmup = 1000, chains = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pscale_rc = pscale.sampling(data = rop_cued, iter = 2000, warmup = 1000, chains = 4, \n",
    "                            control={'max_treedepth': 12, 'adapt_delta': 0.99})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pscale_ru = pscale.sampling(data = rop_uncued, iter = 2000, warmup = 1000, chains = 4, control={'max_treedepth': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pscale2_sc = pscale2.sampling(data = saline_cued, iter = 1600, warmup = 800, chains = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pscale2_su = pscale2.sampling(data = saline_uncued, iter = 1600, warmup = 800, chains = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pscale2_rc = pscale2.sampling(data = rop_cued, iter = 1600, warmup = 800, chains = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pscale2_ru = pscale2.sampling(data = rop_uncued, iter = 1600, warmup = 800, chains = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pindep_sc = pindep.sampling(data = saline_cued, iter = 2000, warmup = 1000, chains = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pindep_su = pindep.sampling(data = saline_uncued, iter = 2000, warmup = 1000, chains = 4,\n",
    "                           control={'adapt_delta': 0.99})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pindep_rc = pindep.sampling(data = rop_cued, iter = 2000, warmup = 1000, chains = 4,\n",
    "                           control={'adapt_delta': 0.99})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pindep_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pindep_ru = pindep.sampling(data = rop_uncued, iter = 1600, warmup = 800, chains = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pindep2_sc = pindep2.sampling(data = saline_cued, iter = 1600, warmup = 800, chains = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pindep2_su = pindep2.sampling(data = saline_uncued, iter = 1600, warmup = 800, chains = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pindep2_rc = pindep2.sampling(data = rop_cued, iter = 1600, warmup = 800, chains = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pindep2_ru = pindep2.sampling(data = rop_uncued, iter = 1600, warmup = 800, chains = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model('pindep_rc_dict.pkl',pindep,pindep_rc,rop_cued)\n",
    "save_model('pindep_sc_dict.pkl',pindep,pindep_sc,saline_cued)\n",
    "save_model('pindep_su_dict.pkl',pindep,pindep_su,saline_uncued)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model('pscale_sc_dict.pkl',pscale,pscale_sc,saline_cued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to save fit:\n",
    "#model and fit must be saved in dictionary together, with the model first\n",
    "def save_model(name,model,fit,data):\n",
    "    model_dict = {'model': model, 'fit': fit, 'data': data}\n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump(model_dict, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load fit:\n",
    "with open('basic_su_dict.pkl', 'rb') as f:\n",
    "    basic_su_dict = pickle.load(f)\n",
    "    \n",
    "#extract model fit from loaded dictionary\n",
    "basic_su = basic_su_dict['fit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting\n",
    "az.plot_trace(basic_su)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overall summary info\n",
    "print(basic_su)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract specific parameters \n",
    "basic_su_summary = basic_su.extract(permuted = True)\n",
    "basic_su_etaneg = basic_su_summary['etaNegative']\n",
    "basic_su_etapos = basic_su_summary['etaPositive']\n",
    "\n",
    "basic_su_etaneg.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to pandas dataframe, and save as a csv file\n",
    "\n",
    "basic_su_df = basic_su.to_dataframe()\n",
    "basic_su_df.to_csv('LM_saline-uncued_basic-fit')\n",
    "\n",
    "#load back in\n",
    "basic_su_df = pd.read_csv('LM_saline-uncued_basic-fit')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
