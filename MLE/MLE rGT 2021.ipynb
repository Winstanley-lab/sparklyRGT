{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum likelihood model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io as sio\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'BH04_raw_acquisition.xlsx'\n",
    "dataset = pd.read_excel(file_name)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pun_Dur</th>\n",
       "      <th>Pellets</th>\n",
       "      <th>Chosen</th>\n",
       "      <th>option</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51713</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51715</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51716</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51717</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51719</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1767 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pun_Dur  Pellets  Chosen  option\n",
       "1970         0        1       2       1\n",
       "1971         0        1       2       1\n",
       "1973         0        1       2       1\n",
       "1974         0        2       5       2\n",
       "1975         0        2       5       2\n",
       "...        ...      ...     ...     ...\n",
       "51713        0        2       5       2\n",
       "51715        0        2       5       2\n",
       "51716        0        2       5       2\n",
       "51717        0        2       5       2\n",
       "51719       10        0       5       2\n",
       "\n",
       "[1767 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.drop(dataset[dataset['Chosen']==0].index, inplace = True) ## removed all rows where 'Chosen' == 0 is true \n",
    "# dataset\n",
    "# 'Chosen == 0' on a premature response or an omission\n",
    "\n",
    "configA = np.array([1, 4, 0, 2, 3])\n",
    "configB = np.array([4, 1, 0, 3, 2])\n",
    "\n",
    "dataset['MSN'].unique() ## the 2 versions of the task\n",
    "\n",
    "dataset['option'] = dataset['MSN'].str.contains(\"B\").values*configB[dataset['Chosen'].astype('int').ravel()-1].astype('int') + \\\n",
    "    dataset['MSN'].str.contains(\"A\").values*configA[dataset['Chosen'].astype('int').ravel()-1].astype('int') \n",
    "## makes a new column called 'option' which stores P1-P4 choice depending on 'Chosen' and version of the task \n",
    "\n",
    "dataset[dataset['Subject'] == 2][['Pun_Dur','Pellets','Chosen','option']]\n",
    "## dataset where subject == 1 (1149 rows), and only shows 4 columns + 'Chosen' != 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "def mylikelihood(params, ch, rew, pun, ntrials):\n",
    "\n",
    "    # params is a 3 vector of beta, etaP, etaN\n",
    "    # ch is a vector of choices (one per trial) (P1-P4 choice)\n",
    "    # rew is a vector of rewards (Pellets)\n",
    "    # pun is a vector of punishments (Pun_Dur)\n",
    "    \n",
    "    V = np.zeros(4) ## V = latent Q values which start at 0 \n",
    "    ## V stores Q value of P1, Q(P2), Q(P3), Q(P4)\n",
    "    beta = params[0] ## takes the first number in the params vector \n",
    "    etaP = params[1]\n",
    "    etaN = params[2]\n",
    "\n",
    "    loglik = 0 ## start at 0\n",
    "    \n",
    "    for t in range(ntrials): \n",
    "    \n",
    "        # now we want to calculate the log likelihood of the choice on the current trial\n",
    "        ## ln(e) = 1\n",
    "        ## log likelihood is ln(p(P#))*** for each choice - and is the sum of each trial \n",
    "        ## each trial, we update loglik (adding to it) depending on the P1-P4 choice\n",
    "        ## simultaneously, we update the respective Q value for a certain choice depending on the outcome (win or lose) \n",
    "        ## p(Px) \"probability of the data given the parameters we pass to the function (beta, etaN, etaP)\"\n",
    "        # we assume the prob of each choice follows a softmax rule\n",
    "        ## the log likelihood is the joint probability of the data (vector of choices, summed because we're logging) given the model and the parameters of the model\n",
    "        # in log this looks like this\n",
    "        \n",
    "        loglik += beta*V[ch[t]-1] - logsumexp(beta*V) \n",
    "        ## ln likelihood is equal to ln(softmax rule)  \n",
    "        ## recall: the log likelihood is just the likelihood (parameters given data) with log***\n",
    "        ## += just adds to current value \n",
    "        ## this depends on their P1-P4 choice V[ch[t] - 1]\n",
    "        ## the following if code depends on the outcome (win or lose) \n",
    "        \n",
    "        if rew[t]>0:\n",
    "            V[ch[t]-1] += etaP*(rew[t] - V[ch[t]-1])\n",
    "            # this is the same as writing\n",
    "            # V[chosen option](new) = V[chosen option](old)* + etaP*(reward - V[chosen option](old))\n",
    "            ## Note that V[chosen option](old)* isn't present in the equation due to the += \n",
    "        else: ## when rew[t] == 0\n",
    "            V[ch[t]-1] += etaN*(-pun[t] - V[ch[t]-1])\n",
    "            ## V[chosen option] = V[chosen option] + etaN*(punishment - V[chosen option])\n",
    "            ## decreases the Q value (V)\n",
    "            ## punishment is experienced time-out duration in seconds (assumes m is 1 in this example)\n",
    "\n",
    "    return -loglik #easier to minimize than maximize \n",
    "\n",
    "##function: note how loglik is accumulating in magnitude with each trial, and how only one V updates per trial \n",
    "##what does the loglik value represent?*** why do we want to minimize/maximize it?*** ### answered above "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = range(ntrials)\n",
    "# t\n",
    "choices[t]-1 ## holds an array of (P1-P4 choice - 1) for each trial (ex. P1 - 1 = 0 in the array)\n",
    "V = np.zeros(4) \n",
    "# V\n",
    "V[choices[t]-1] ## irrelevant storage --> function:\n",
    "## V[0] stores Q(P1), therefore, we must subtract 1 from choices[t] in order to update the correct value in V\n",
    "\n",
    "beta = 10\n",
    "\n",
    "V_test = np.array([1,1,1,1])\n",
    "V_test\n",
    "\n",
    "logsumexp(beta*V_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "np.log(np.sum(np.exp(a)))\n",
    "a\n",
    "\n",
    "np.exp(a) ## e^x\n",
    "np.sum(a)\n",
    "np.sum(np.exp(a))\n",
    "# np.log(a) #ln, not log \n",
    "np.log(np.sum(np.exp(a)))\n",
    "logsumexp(a) ## same value as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE code again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28855.6971560019"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull out the information we need for MLE\n",
    "\n",
    "#this is for subject 2 only\n",
    "\n",
    "# .values squashes the pandas Series back to a numpy array\n",
    "## pandas Series is a one column dataframe \n",
    "## numpy array is different - can iterate through \n",
    "choices = dataset.loc[dataset['Subject']==2,'option'].values \n",
    "## for subject 2, outputs an array of P1-P4 choice (stored in 'option' column) for each trial \n",
    "## recall: 'Chosen' == 0 was removed \n",
    "\n",
    "rewards = dataset.loc[dataset['Subject']==2,'Pellets'].values \n",
    "## outputs number of pellets rewarded per trial ('Chosen != 0') --> 0 means they lost \n",
    "\n",
    "punishments = dataset.loc[dataset['Subject']==2,'Pun_Dur'].values\n",
    "## outputs punishment durations --> 0 means they won, and ex) 40 means they wait for 40sec\n",
    "\n",
    "ntrials = len(punishments)\n",
    "## punishments was arbitrary --> ntrials stores the number of trials for this subject (can we assume each subject only played one version - MSN? \n",
    "# --> yes must check)\n",
    "\n",
    "# now I can test the likelihood with some fixed parameter values...\n",
    "test_parameters = [10,0.5,0.5] ## random values \n",
    "mylikelihood(test_parameters, choices, rewards, punishments, ntrials)\n",
    "\n",
    "# now we know our function works!!!\n",
    "\n",
    "#this prints out the negative log likelihood, which is the number we want to minimize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choices = dataset.loc[dataset['Subject']==2,'option'].values\n",
    "# choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 541.6397693014861\n",
       " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([ 0.00017053, -0.00017053,  0.00267164])\n",
       "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 84\n",
       "      nit: 19\n",
       "     njev: 21\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([2.96881148, 0.07157529, 0.00535836])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can ask the optimizer to find the parameter values that minimize the negative log likelihood calculated by our function!\n",
    "\n",
    "## test_parameters are an educated initialization\n",
    "## args = additional arguments \n",
    "## bounds are respective to beta, etaP, etaN\n",
    "# len(punishments)\n",
    "\n",
    "results = minimize(mylikelihood,test_parameters,args=(choices,rewards,punishments,ntrials),bounds=((0, None), (0, 1), (0, 1)))\n",
    "results\n",
    "## minimize --> a function that finds the parameter values that minimize the negative log-likelihood calculated by our function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "541.6397693017077 2.9688093520914305 0.07157527370521578 0.005358344008024617\n",
      "1\n",
      "541.6397693015044 2.96881096700948 0.07157532767872697 0.005358353540880911\n",
      "2\n",
      "541.6397693016222 2.968810544484767 0.07157529546885705 0.005358342216925646\n"
     ]
    }
   ],
   "source": [
    "# usually, you will iterate over 3-5 minimize calls, with different random starting points, and choose the one with the \n",
    "# highest (ie, lowest negative) likelihood (lowest -loglik)\n",
    "\n",
    "## highest loglik (least negative, closest to 0) is at the combination of parameters that best fit the data (the ML parameter estimates) \n",
    "## lowest -loglik is the same thing!^ ***\n",
    "## the combination of parameters that best fit the data (variable) will minimize -loglik - recall: L(theta | y) \n",
    "## we pass random initiatlizations to each parameter value\n",
    "\n",
    "init = 3 # three different initializations\n",
    "\n",
    "estimates = np.zeros([init,4]) ## stores array of zeros, 3 rows of 4 zeros each \n",
    "\n",
    "for n in range(init): ## range 0-3\n",
    "    print(n)\n",
    "    \n",
    "    res = minimize(mylikelihood,[10+np.random.rand()*10,0.5+np.random.rand()*0.2,0.5+np.random.rand()*0.2],\n",
    "                   args=(choices,rewards,punishments,ntrials),bounds=((0, None), (0, 1), (0, 1))) \n",
    "    ## res is the minimize function, with the addition of random numbers to beta, etaP and etaN \n",
    "\n",
    "    print(res.fun, res.x[0], res.x[1], res.x[2])\n",
    "    estimates[n,:] = [res.fun, res.x[0], res.x[1], res.x[2]]\n",
    "\n",
    "\n",
    "#for the print out - 1st value is the minimized negative log likelihood\n",
    "#second value is the beta parameter\n",
    "#third value is the etaP parameter\n",
    "#fourth value is the etaN parameter\n",
    "\n",
    "## res.fun calls the 'fun' field in res \n",
    "## 0 1 2 represent the 1st, 2nd and 3rd initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates_test = np.zeros((3,4)) \n",
    "estimates_test\n",
    "range(init) \n",
    "np.random.rand()\n",
    "\n",
    "np.linspace(0, 5, 11)\n",
    "np.linspace(0.005,0.1,21)\n",
    "\n",
    "np.zeros([len(beta), len(etaP)]) ## 11 rows of 21 zeros each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is useful to plot the entire likelihood surface for your data given the model\n",
    "\n",
    "beta = np.linspace(0,5,11) ##between 0 and 5, gives 11 evenly spaced out values from 0 to 5\n",
    "etaP = np.linspace(0.005,0.1,21) \n",
    "etaN = 0.00536\n",
    "\n",
    "nll = np.zeros([len(beta),len(etaP)])\n",
    "\n",
    "for b in range(len(beta)):\n",
    "    for e in range(len(etaP)):\n",
    "        \n",
    "        nll[b,e] = mylikelihood([beta[b],etaP[e],etaN],choices,rewards,punishments,ntrials)\n",
    "        \n",
    "        ## for beta = 0, etaP = 0.005 --> -loglik = 2449.58\n",
    "        ## for beta = 0, etaP = 0.00975 --> -loglik = 2449.58 \n",
    "        ## function: for each b, test the 21 etaP values, output the -loglik (from mylikelihood)\n",
    "        ## output: 11*21 -loglik values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2449.5821361 , 2449.5821361 , 2449.5821361 , 2449.5821361 ,\n",
       "        2449.5821361 , 2449.5821361 , 2449.5821361 , 2449.5821361 ,\n",
       "        2449.5821361 , 2449.5821361 , 2449.5821361 , 2449.5821361 ,\n",
       "        2449.5821361 , 2449.5821361 , 2449.5821361 , 2449.5821361 ,\n",
       "        2449.5821361 , 2449.5821361 , 2449.5821361 , 2449.5821361 ,\n",
       "        2449.5821361 ],\n",
       "       [2549.26190037, 2031.21467986, 1845.78857026, 1755.74097039,\n",
       "        1704.59900756, 1672.80093978, 1651.96089041, 1637.93825399,\n",
       "        1628.46526124, 1622.1956233 , 1618.2768792 , 1616.14036945,\n",
       "        1615.39035368, 1615.74177522, 1616.98343454, 1618.95517248,\n",
       "        1621.53315647, 1624.6200571 , 1628.13829005, 1632.02524536,\n",
       "        1636.22984385],\n",
       "       [2698.87568456, 1712.43905867, 1411.49324333, 1278.85488325,\n",
       "        1207.57038216, 1164.50295735, 1136.58011908, 1117.74785293,\n",
       "        1104.85263611, 1096.09363757, 1090.36348467, 1086.93912166,\n",
       "        1085.32497709, 1085.16788061, 1086.20812094, 1088.24980437,\n",
       "        1091.14207188, 1094.76671972, 1099.02975916, 1103.85549337,\n",
       "        1109.18225762],\n",
       "       [2896.63766216, 1473.14582535, 1112.07736107,  971.49653708,\n",
       "         901.08480053,  860.0419864 ,  833.77642256,  816.01396986,\n",
       "         803.66784968,  795.05047059,  789.15720348,  785.3473863 ,\n",
       "         783.18940193,  782.3796439 ,  782.69726173,  783.97737041,\n",
       "         786.0943497 ,  788.95095294,  792.47092372,  796.59382389,\n",
       "         801.27130973],\n",
       "       [3139.17717098, 1293.75974837,  910.83655199,  782.35550072,\n",
       "         723.26359543,  690.25065219,  669.43364047,  655.3158643 ,\n",
       "         645.35727696,  638.23199824,  633.17602092,  629.71274186,\n",
       "         627.5258872 ,  626.39559488,  626.1637843 ,  626.71408929,\n",
       "         627.9595097 ,  629.8344021 ,  632.28904598,  635.28581557,\n",
       "         638.79639708],\n",
       "       [3422.01940748, 1158.17524142,  777.82486145,  670.96656399,\n",
       "         626.88426537,  603.59888896,  589.21085855,  579.4448521 ,\n",
       "         572.46968385,  567.38095303,  563.67596724,  561.04756253,\n",
       "         559.29419165,  558.27686976,  557.89669058,  558.08210168,\n",
       "         558.7811602 ,  559.95651238,  561.58196199,  563.64002103,\n",
       "         566.12009852],\n",
       "       [3740.12821483, 1054.31742562,  691.61804605,  609.93304705,\n",
       "         581.30877853,  567.59985042,  559.47270328,  553.99399169,\n",
       "         550.04852787,  547.13517191,  544.99188106,  543.46315627,\n",
       "         542.44784163,  541.87632558,  541.6994704 ,  541.8826281 ,\n",
       "         542.40206204,  543.24261439,  544.39607945,  545.86001044,\n",
       "         547.63681046],\n",
       "       [4088.38876145,  973.56236857,  637.78633046,  581.86665821,\n",
       "         567.88450733,  562.99179043,  560.59819242,  559.08255173,\n",
       "         557.99607722,  557.20137358,  556.64892376,  556.3151454 ,\n",
       "         556.18512099,  556.24809911,  556.49655354,  556.92611031,\n",
       "         557.53559783,  558.32705093,  559.30565804,  560.47967344,\n",
       "         561.86031482],\n",
       "       [4461.96115341,  909.87946794,  606.78248978,  575.87652237,\n",
       "         575.3404973 ,  578.38641901,  581.13746591,  583.19832581,\n",
       "         584.72422472,  585.90176077,  586.86872774,  587.71698662,\n",
       "         588.50663603,  589.27777532,  590.05848981,  590.86995739,\n",
       "         591.72966508,  592.65344622,  593.6567947 ,  594.75573755,\n",
       "         595.96743636],\n",
       "       [4856.49171069,  859.06851155,  592.24396713,  585.04185711,\n",
       "         596.72450538,  606.88254993,  614.22754938,  619.48954871,\n",
       "         623.36835966,  626.34011545,  628.70922521,  630.6699289 ,\n",
       "         632.34866124,  633.83032499,  635.17421762,  636.4237342 ,\n",
       "         637.61238375,  638.76761451,  639.91332187,  641.0715525 ,\n",
       "         642.26371029],\n",
       "       [5268.20466684,  818.18466112,  589.84295794,  604.84679496,\n",
       "         627.6146875 ,  644.15855163,  655.61504365,  663.74186668,\n",
       "         669.73120034,  674.31995462,  677.96234456,  680.94452908,\n",
       "         683.45240021,  685.61093518,  687.50728035,  689.20459032,\n",
       "         690.75055436,  692.18281377,  693.53252171,  694.82677023,\n",
       "         696.09031306]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nll stores the likelihoods for each of the parameter values stored in beta and etaP \n",
    "nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<matplotlib.axis.XTick at 0x1af7b99af70>,\n",
       "  <matplotlib.axis.XTick at 0x1af7b99aac0>],\n",
       " [Text(0, 0, '0'), Text(20, 0, '0.1')],\n",
       " [<matplotlib.axis.YTick at 0x1af75cc3610>,\n",
       "  <matplotlib.axis.YTick at 0x1af75cc3280>],\n",
       " [Text(0, 0, '0'), Text(0, 10, '5')]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this plots the likelihood surface --> best parameter fits are at the darkest colour (minimum negative LL)\n",
    "\n",
    "#from the MLE function a few cells above, we know the best fits are at beta = 2.97, and etaP = .07\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=[15,8])\n",
    "\n",
    "im = ax.imshow(nll)\n",
    "fig.colorbar(im,ax=ax)\n",
    "ax.set(xticks=[0,20],xticklabels=[0,.1],yticks=[0,10],yticklabels=[0,5])\n",
    "\n",
    "## likelihood surface \n",
    "## slice of likelihood surface at etaN = 0.00536\n",
    "## y axis is beta, x-axis is etaP \n",
    "## axis towards me is -loglik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541.6397693016222 2.968810544484767 0.07157529546885705 0.005358342216925646\n",
      "1\n",
      "541.6397693016222 2.968810544484767 0.07157529546885705 0.005358342216925646\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-ddbe9c5b81a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         res_test = minimize(mylikelihood,[10+np.random.rand()*10,0.5+np.random.rand()*0.2,0.5+np.random.rand()*0.2],\n\u001b[0m\u001b[0;32m     24\u001b[0m                        args=(choices,rewards,punishments,ntrials),bounds=((0, None), (0, 1), (0, 1)))\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    615\u001b[0m                                   **options)\n\u001b[0;32m    616\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[0;32m    618\u001b[0m                                 callback=callback, **options)\n\u001b[0;32m    619\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    199\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_grad\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_grad\u001b[1;34m()\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mngev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m                 self.g = approx_derivative(fun_wrapped, self.x, f0=self.f,\n\u001b[0m\u001b[0;32m     92\u001b[0m                                            **finite_diff_options)\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_numdiff.py\u001b[0m in \u001b[0;36mapprox_derivative\u001b[1;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msparsity\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m             return _dense_difference(fun_wrapped, x0, f0, h,\n\u001b[0m\u001b[0;32m    427\u001b[0m                                      use_one_sided, method)\n\u001b[0;32m    428\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_numdiff.py\u001b[0m in \u001b[0;36m_dense_difference\u001b[1;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh_vecs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[0mdx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Recompute dx as exactly representable number.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'3-point'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0muse_one_sided\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m             \u001b[0mx1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh_vecs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_numdiff.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m             raise RuntimeError(\"`fun` return value has \"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-025669f39878>\u001b[0m in \u001b[0;36mmylikelihood\u001b[1;34m(params, ch, rew, pun, ntrials)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# in log this looks like this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mloglik\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;31m## ln likelihood is equal to ln(softmax rule)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m## recall: the log likelihood is just the likelihood (parameters given data) with log***\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\special\\_logsumexp.py\u001b[0m in \u001b[0;36mlogsumexp\u001b[1;34m(a, axis, b, keepdims, return_sign)\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[0ma_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0ma_max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2703\u001b[0m     \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2704\u001b[0m     \"\"\"\n\u001b[1;32m-> 2705\u001b[1;33m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0m\u001b[0;32m   2706\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0;32m   2707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# subjects\n",
    "# estimates\n",
    "# range(len(subjects)) ## issue: there is no subject 0 \n",
    "\n",
    "# now we can do this over all subjects\n",
    "\n",
    "init = 3\n",
    "subjects = dataset['Subject'].unique()\n",
    "estimates = np.zeros([len(subjects),init,4])\n",
    "for sub in range(len(subjects)):\n",
    "    print(f'Subject {subjects[sub]}...')\n",
    "    \n",
    "    choices = dataset.loc[dataset['Subject']==subjects[sub],'option'].values\n",
    "\n",
    "    rewards = dataset.loc[dataset['Subject']==subjects[sub],'Pellets'].values\n",
    "\n",
    "    punishments = dataset.loc[dataset['Subject']==subjects[sub],'Pun_Dur'].values\n",
    "    \n",
    "    ntrials = len(punishments)\n",
    "    \n",
    "    for n in range(init):\n",
    "        print(n)\n",
    "        res_test = minimize(mylikelihood,[10+np.random.rand()*10,0.5+np.random.rand()*0.2,0.5+np.random.rand()*0.2],\n",
    "                       args=(choices,rewards,punishments,ntrials),bounds=((0, None), (0, 1), (0, 1)))\n",
    "    \n",
    "        print(res.fun, res.x[0], res.x[1], res.x[2])\n",
    "        estimates[sub,n,:] = [res.fun, res.x[0], res.x[1], res.x[2]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
