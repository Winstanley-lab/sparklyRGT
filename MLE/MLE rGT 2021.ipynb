{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum likelihood model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io as sio\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'BH04_raw_acquisition.xlsx'\n",
    "dataset = pd.read_excel(file_name)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pun_Dur</th>\n",
       "      <th>Pellets</th>\n",
       "      <th>Chosen</th>\n",
       "      <th>option</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51713</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51715</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51716</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51717</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51719</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1767 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pun_Dur  Pellets  Chosen  option\n",
       "1970         0        1       2       1\n",
       "1971         0        1       2       1\n",
       "1973         0        1       2       1\n",
       "1974         0        2       5       2\n",
       "1975         0        2       5       2\n",
       "...        ...      ...     ...     ...\n",
       "51713        0        2       5       2\n",
       "51715        0        2       5       2\n",
       "51716        0        2       5       2\n",
       "51717        0        2       5       2\n",
       "51719       10        0       5       2\n",
       "\n",
       "[1767 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.drop(dataset[dataset['Chosen']==0].index, inplace = True) ## removed all rows where 'Chosen' == 0 is true \n",
    "# dataset\n",
    "# 'Chosen == 0' on a premature response or an omission\n",
    "\n",
    "configA = np.array([1, 4, 0, 2, 3])\n",
    "configB = np.array([4, 1, 0, 3, 2])\n",
    "\n",
    "dataset['MSN'].unique() ## the 2 versions of the task\n",
    "\n",
    "dataset['option'] = dataset['MSN'].str.contains(\"B\").values*configB[dataset['Chosen'].astype('int').ravel()-1].astype('int') + \\\n",
    "    dataset['MSN'].str.contains(\"A\").values*configA[dataset['Chosen'].astype('int').ravel()-1].astype('int') \n",
    "## makes a new column called 'option' which stores P1-P4 choice depending on 'Chosen' and version of the task \n",
    "\n",
    "dataset[dataset['Subject'] == 2][['Pun_Dur','Pellets','Chosen','option']]\n",
    "## dataset where subject == 1 (1149 rows), and only shows 4 columns + 'Chosen' != 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "def mylikelihood(params, ch, rew, pun, ntrials):\n",
    "\n",
    "    # params is a 3 vector of beta, etaP, etaN\n",
    "    # ch is a vector of choices (one per trial) (P1-P4 choice)\n",
    "    # rew is a vector of rewards (Pellets)\n",
    "    # pun is a vector of punishments (Pun_Dur)\n",
    "    \n",
    "    V = np.zeros(4) ## V = latent Q values which start at 0 \n",
    "    ## V stores Q value of (P1), Q(P2), Q(P3), Q(P4)\n",
    "    beta = params[0] ## takes the first number in the params vector \n",
    "    etaP = params[1]\n",
    "    etaN = params[2]\n",
    "\n",
    "    loglik = 0 ## start at 0\n",
    "    \n",
    "    for t in range(ntrials): \n",
    "    \n",
    "        # now we want to calculate the log likelihood of the choice on the current trial\n",
    "        ## ln(e) = 1\n",
    "        ## log likelihood is p(P#) \n",
    "        ## p(Px) \"probability of the data given the parameters we pass to the function (beta, etaN, etaP)\"\n",
    "        # we assume the prob of each choice follows a softmax rule\n",
    "        # in log this looks like this\n",
    "        \n",
    "        loglik += beta*V[ch[t]-1] - logsumexp(beta*V) \n",
    "        ## log (ln) likelihood is equal to some formula involving beta, V, ch, and t --> gives us the log likelihood of the choice on the current trial \n",
    "        ## recall: the log likelihood is just the likelihood (parameters given data) with log\n",
    "        ## += just adds to current value \n",
    "        \n",
    "        if rew[t]>0:\n",
    "            V[ch[t]-1] += etaP*(rew[t] - V[ch[t]-1])\n",
    "            # this is the same as writing\n",
    "            # V[chosen option] = V[chosen option] + etaP*(reward - V[chosen option])\n",
    "        else:\n",
    "            V[ch[t]-1] += etaN*(-pun[t] - V[ch[t]-1])\n",
    "            ## V[chosen option] = V[chosen option] + etaN*(punishment - V[chosen option])\n",
    "            ## decreases the Q value (V)\n",
    "\n",
    "    return -loglik #easier to minimize than maximize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28855.6971560019"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull out the information we need for MLE\n",
    "\n",
    "#this is for subject 2 only\n",
    "\n",
    "# .values squashes the pandas Series back to a numpy array\n",
    "## pandas Series is a one column dataframe \n",
    "## numpy array is different - can iterate through \n",
    "choices = dataset.loc[dataset['Subject']==2,'option'].values \n",
    "## for subject 2, outputs an array of P1-P4 choice (stored in 'option' column) for each trial \n",
    "## recall: 'Chosen' == 0 was removed \n",
    "\n",
    "rewards = dataset.loc[dataset['Subject']==2,'Pellets'].values \n",
    "## outputs number of pellets rewarded per trial ('Chosen != 0') --> 0 means they lost \n",
    "\n",
    "punishments = dataset.loc[dataset['Subject']==2,'Pun_Dur'].values\n",
    "## outputs punishment durations --> 0 means they won, and ex) 40 means they wait for 40sec\n",
    "\n",
    "ntrials = len(punishments)\n",
    "## punishments was arbitrary --> ntrials stores the number of trials for this subject (can we assume each subject only played one version - MSN? \n",
    "# --> yes must check)\n",
    "\n",
    "# now I can test the likelihood with some fixed parameter values...\n",
    "test_parameters = [10,0.5,0.5] ## random values \n",
    "mylikelihood(test_parameters, choices, rewards, punishments, ntrials)\n",
    "\n",
    "# now we know our function works!!!\n",
    "\n",
    "#this prints out the negative log likelihood, which is the number we want to minimize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choices = dataset.loc[dataset['Subject']==2,'option'].values\n",
    "choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-2ca4d646b6ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpunishments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmylikelihood\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_parameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchoices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpunishments\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mntrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m### I don't know how this works\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m# results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# help(minimize)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    615\u001b[0m                                   **options)\n\u001b[0;32m    616\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[0;32m    618\u001b[0m                                 callback=callback, **options)\n\u001b[0;32m    619\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m     \u001b[1;31m# unbounded variables must use None, not +-inf, for optimizer to work properly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m     \u001b[0mbounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mu\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbounds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m     \u001b[1;31m# LBFGSB is sent 'old-style' bounds, 'new-style' bounds are required by\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[1;31m# approx_derivative and ScalarFunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m     \u001b[1;31m# unbounded variables must use None, not +-inf, for optimizer to work properly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m     \u001b[0mbounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mu\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbounds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m     \u001b[1;31m# LBFGSB is sent 'old-style' bounds, 'new-style' bounds are required by\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[1;31m# approx_derivative and ScalarFunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "# now we can ask the optimizer to find the parameter values that minimize the negative log likelihood calculated by our function!\n",
    "\n",
    "## test_parameters are an educated initialization\n",
    "## args = additional arguments \n",
    "## bounds are respective to beta, etaP, etaN\n",
    "len(punishments)\n",
    "\n",
    "results = minimize(mylikelihood,test_parameters,args=(choices,rewards,punishments,ntrials),bounds=((0, None), (0, 1), (0, 1))) ### I don't know how this works \n",
    "results\n",
    "# help(minimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "541.6397693016298 2.968809871593598 0.07157525680887017 0.005358345884407336\n",
      "1\n",
      "541.6397693020784 2.9688130443743237 0.07157560859899692 0.00535837936983855\n",
      "2\n",
      "541.639769305799 2.968801783988867 0.07157524442374341 0.005358309684260003\n"
     ]
    }
   ],
   "source": [
    "# usually, you will iterate over 3-5 minimize calls, with different random starting points, and choose the one with the \n",
    "# highest (ie, lowest negative) likelihood (lowest -loglik)\n",
    "\n",
    "init = 3 # three different initializations\n",
    "\n",
    "estimates = np.zeros([init,4])\n",
    "\n",
    "for n in range(init):\n",
    "    print(n)\n",
    "    \n",
    "    res = minimize(mylikelihood,[10+np.random.rand()*10,0.5+np.random.rand()*0.2,0.5+np.random.rand()*0.2],args=(choices,rewards,punishments,ntrials),bounds=((0, None), (0, 1), (0, 1)))\n",
    "\n",
    "    print(res.fun, res.x[0], res.x[1], res.x[2])\n",
    "    estimates[n,:] = [res.fun, res.x[0], res.x[1], res.x[2]]\n",
    "\n",
    "\n",
    "#for the print out - 1st value is the  minimized negative log likelihood\n",
    "#second value is the beta parameter\n",
    "#third value is the etaP parameter\n",
    "#fourth value is the etaN parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is useful to plot the entire likelihood surface for your data given the model\n",
    "\n",
    "beta = np.linspace(0,5,11) ##between 0 and 5, give us 10 evenly spaced out values \n",
    "etaP = np.linspace(0.005,0.1,21)\n",
    "etaN = 0.00536\n",
    "\n",
    "nll = np.zeros([len(beta),len(etaP)])\n",
    "\n",
    "for b in range(len(beta)):\n",
    "    for e in range(len(etaP)):\n",
    "        \n",
    "        nll[b,e] = mylikelihood([beta[b],etaP[e],etaN],choices,rewards,punishments,ntrials)\n",
    "        \n",
    "        ## for beta = 0, etaP = 0.005 --> -loglik = 2449.58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2449.5821361 , 2449.5821361 , 2449.5821361 , 2449.5821361 ,\n",
       "        2449.5821361 , 2449.5821361 , 2449.5821361 , 2449.5821361 ,\n",
       "        2449.5821361 , 2449.5821361 , 2449.5821361 , 2449.5821361 ,\n",
       "        2449.5821361 , 2449.5821361 , 2449.5821361 , 2449.5821361 ,\n",
       "        2449.5821361 , 2449.5821361 , 2449.5821361 , 2449.5821361 ,\n",
       "        2449.5821361 ],\n",
       "       [2549.26190037, 2031.21467986, 1845.78857026, 1755.74097039,\n",
       "        1704.59900756, 1672.80093978, 1651.96089041, 1637.93825399,\n",
       "        1628.46526124, 1622.1956233 , 1618.2768792 , 1616.14036945,\n",
       "        1615.39035368, 1615.74177522, 1616.98343454, 1618.95517248,\n",
       "        1621.53315647, 1624.6200571 , 1628.13829005, 1632.02524536,\n",
       "        1636.22984385],\n",
       "       [2698.87568456, 1712.43905867, 1411.49324333, 1278.85488325,\n",
       "        1207.57038216, 1164.50295735, 1136.58011908, 1117.74785293,\n",
       "        1104.85263611, 1096.09363757, 1090.36348467, 1086.93912166,\n",
       "        1085.32497709, 1085.16788061, 1086.20812094, 1088.24980437,\n",
       "        1091.14207188, 1094.76671972, 1099.02975916, 1103.85549337,\n",
       "        1109.18225762],\n",
       "       [2896.63766216, 1473.14582535, 1112.07736107,  971.49653708,\n",
       "         901.08480053,  860.0419864 ,  833.77642256,  816.01396986,\n",
       "         803.66784968,  795.05047059,  789.15720348,  785.3473863 ,\n",
       "         783.18940193,  782.3796439 ,  782.69726173,  783.97737041,\n",
       "         786.0943497 ,  788.95095294,  792.47092372,  796.59382389,\n",
       "         801.27130973],\n",
       "       [3139.17717098, 1293.75974837,  910.83655199,  782.35550072,\n",
       "         723.26359543,  690.25065219,  669.43364047,  655.3158643 ,\n",
       "         645.35727696,  638.23199824,  633.17602092,  629.71274186,\n",
       "         627.5258872 ,  626.39559488,  626.1637843 ,  626.71408929,\n",
       "         627.9595097 ,  629.8344021 ,  632.28904598,  635.28581557,\n",
       "         638.79639708],\n",
       "       [3422.01940748, 1158.17524142,  777.82486145,  670.96656399,\n",
       "         626.88426537,  603.59888896,  589.21085855,  579.4448521 ,\n",
       "         572.46968385,  567.38095303,  563.67596724,  561.04756253,\n",
       "         559.29419165,  558.27686976,  557.89669058,  558.08210168,\n",
       "         558.7811602 ,  559.95651238,  561.58196199,  563.64002103,\n",
       "         566.12009852],\n",
       "       [3740.12821483, 1054.31742562,  691.61804605,  609.93304705,\n",
       "         581.30877853,  567.59985042,  559.47270328,  553.99399169,\n",
       "         550.04852787,  547.13517191,  544.99188106,  543.46315627,\n",
       "         542.44784163,  541.87632558,  541.6994704 ,  541.8826281 ,\n",
       "         542.40206204,  543.24261439,  544.39607945,  545.86001044,\n",
       "         547.63681046],\n",
       "       [4088.38876145,  973.56236857,  637.78633046,  581.86665821,\n",
       "         567.88450733,  562.99179043,  560.59819242,  559.08255173,\n",
       "         557.99607722,  557.20137358,  556.64892376,  556.3151454 ,\n",
       "         556.18512099,  556.24809911,  556.49655354,  556.92611031,\n",
       "         557.53559783,  558.32705093,  559.30565804,  560.47967344,\n",
       "         561.86031482],\n",
       "       [4461.96115341,  909.87946794,  606.78248978,  575.87652237,\n",
       "         575.3404973 ,  578.38641901,  581.13746591,  583.19832581,\n",
       "         584.72422472,  585.90176077,  586.86872774,  587.71698662,\n",
       "         588.50663603,  589.27777532,  590.05848981,  590.86995739,\n",
       "         591.72966508,  592.65344622,  593.6567947 ,  594.75573755,\n",
       "         595.96743636],\n",
       "       [4856.49171069,  859.06851155,  592.24396713,  585.04185711,\n",
       "         596.72450538,  606.88254993,  614.22754938,  619.48954871,\n",
       "         623.36835966,  626.34011545,  628.70922521,  630.6699289 ,\n",
       "         632.34866124,  633.83032499,  635.17421762,  636.4237342 ,\n",
       "         637.61238375,  638.76761451,  639.91332187,  641.0715525 ,\n",
       "         642.26371029],\n",
       "       [5268.20466684,  818.18466112,  589.84295794,  604.84679496,\n",
       "         627.6146875 ,  644.15855163,  655.61504365,  663.74186668,\n",
       "         669.73120034,  674.31995462,  677.96234456,  680.94452908,\n",
       "         683.45240021,  685.61093518,  687.50728035,  689.20459032,\n",
       "         690.75055436,  692.18281377,  693.53252171,  694.82677023,\n",
       "         696.09031306]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nll stores the likelihoods for each of the parameter values stored in beta and etaP \n",
    "nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<matplotlib.axis.XTick at 0x276f3cb8040>,\n",
       "  <matplotlib.axis.XTick at 0x276f3cb8400>],\n",
       " [Text(0, 0, '0'), Text(20, 0, '0.1')],\n",
       " [<matplotlib.axis.YTick at 0x276f3cb8490>,\n",
       "  <matplotlib.axis.YTick at 0x276f3cb8bb0>],\n",
       " [Text(0, 0, '0'), Text(0, 10, '5')]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this plots the likelihood surface --> best parameter fits are at the darkest colour (minimum negative LL)\n",
    "\n",
    "#from the MLE function a few cells above, we know the best fits are at beta = 2.97, and etaP = .07\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=[15,8])\n",
    "\n",
    "im = ax.imshow(nll)\n",
    "fig.colorbar(im,ax=ax)\n",
    "ax.set(xticks=[0,20],xticklabels=[0,.1],yticks=[0,10],yticklabels=[0,5])\n",
    "\n",
    "## likelihood surface \n",
    "## slice of likelihood surface at etaN = 0.00536\n",
    "## y axis is beta, x-axis is etaP \n",
    "## axis towards me is -loglik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 9...\n",
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1086 is out of bounds for axis 0 with size 1086",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-3b5dc2676ee6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmylikelihood\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchoices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpunishments\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mntrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    615\u001b[0m                                   **options)\n\u001b[0;32m    616\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[0;32m    618\u001b[0m                                 callback=callback, **options)\n\u001b[0;32m    619\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[0miprint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m     sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n\u001b[0m\u001b[0;32m    307\u001b[0m                                   \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_bounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m                                   finite_diff_rel_step=finite_diff_rel_step)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_prepare_scalar_function\u001b[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;31m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;31m# calculation reduces overall function evaluations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m     sf = ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0m\u001b[0;32m    262\u001b[0m                         finite_diff_rel_step, bounds, epsilon=epsilon)\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;31m# Gradient evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-c92e4ded4835>\u001b[0m in \u001b[0;36mmylikelihood\u001b[1;34m(params, ch, rew, pun, ntrials)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# in log this looks like this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mloglik\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;31m## log (ln) likelihood is equal to some formula involving beta, V, ch, and t --> gives us the log likelihood of the choice on the current trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m## recall: the log likelihood is just the likelihood (parameters given data) with log\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1086 is out of bounds for axis 0 with size 1086"
     ]
    }
   ],
   "source": [
    "# now we can do this over all subjects\n",
    "\n",
    "init = 3 # three different initializations\n",
    "\n",
    "subjects = dataset['Subject'].unique()\n",
    "\n",
    "estimates = np.zeros([len(subjects),init,4])\n",
    "\n",
    "for sub in range(len(subjects)):\n",
    "    \n",
    "    print(f'Subject {subjects[sub]}...')\n",
    "    \n",
    "    choices = dataset.loc[dataset['Subject']==subjects[sub],'option'].values\n",
    "\n",
    "    rewards = dataset.loc[dataset['Subject']==subjects[sub],'Pellets'].values\n",
    "\n",
    "    punishments = dataset.loc[dataset['Subject']==subjects[sub],'Pun_Dur'].values\n",
    "\n",
    "    for n in range(init):\n",
    "        print(n)\n",
    "\n",
    "        res = minimize(mylikelihood,[10+np.random.rand()*10,0.5+np.random.rand()*0.2,0.5+np.random.rand()*0.2],args=(choices,rewards,punishments,ntrials),bounds=((0, None), (0, 1), (0, 1)))\n",
    "\n",
    "        print(res.fun, res.x[0], res.x[1], res.x[2])\n",
    "        estimates[sub,n,:] = [res.fun, res.x[0], res.x[1], res.x[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
